{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "preprocess_nd_EDA.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyN5OcvE0lEuDG/W04iZ3gpW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/karyam/RGNN/blob/main/preprocess_nd_EDA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4DHmn8zTpJrr"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os, sys\n",
        "import tensorflow as tf\n",
        "import tensorboard\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JxFzsE95pR48"
      },
      "source": [
        "#globals\n",
        "FEATURES_DATA_PATH = \"drive/My Drive/BCI/code/data/SEED/ExtractedFeatures\"\n",
        "PREPROCESSED_DATA_PATH = \"drive/My Drive/BCI/code/data/SEED/Preprocessed_EEG\"\n",
        "CSV_PATH = \"drive/My Drive/BCI_clone/CSV\"\n",
        "SUBJECT_CSV_PATH = CSV_PATH + \"/\" + \"csv_0.csv\"\n",
        "ALL_SUBJECTS_CSV_PATH = CSV_PATH + \"/\" + \"csv_all_subjects.csv\"\n",
        "\n",
        "# sampling frequency\n",
        "sf = 200\n",
        "\n",
        "# hyper-parameters\n",
        "num_trials = 15\n",
        "num_subjects = 15\n",
        "num_bands = 5\n",
        "num_classes = 3\n",
        "batch_size = 32"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6166y69sqWPX"
      },
      "source": [
        "#### Examine data format"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "31cMuKjhph-u"
      },
      "source": [
        "# get only subject data and sort for convenience\n",
        "data = os.listdir(FEATURES_DATA_PATH)\n",
        "# only take subject files\n",
        "data = [x for x in data if len(x.split(\"_\")) == 2] \n",
        "data.sort(key = lambda x : int(x.split(\"_\")[0]))\n",
        "# 3 files per subject, each file contains recordings for 15 trials\n",
        "assert (len(data) == 45)\n",
        "\n",
        "# load one sample \n",
        "sample = io.loadmat(os.path.join(FEATURES_DATA_PATH, data[0]))\n",
        "\n",
        "keys = list(sample.keys())\n",
        "assert (len(keys) == (2*6*15+3)) # 3 meta keys\n",
        "print(\"One sample shape: (num_channels, num_windows, num_bands)\")\n",
        "print(sample[\"de_LDS1\"].shape)\n",
        "\n",
        "# get all features averaged with LDS\n",
        "features_LDS = keys[4::2]\n",
        "print(\"Feature names LDS averaged\")\n",
        "print(features_LDS)\n",
        "assert (len(features_LDS) == (15*6))\n",
        "\n",
        "labels = io.loadmat(os.path.join(FEATURES_DATA_PATH, \"label.mat\"))\n",
        "labels = np.squeeze(labels[\"label\"] + np.ones(15, dtype=np.int8))\n",
        "assert (labels.shape == (15,))\n",
        "print(type(labels[0]))\n",
        "print(labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3keDbUYmpmAP"
      },
      "source": [
        "# get the range of values across samples from de_LDS feature\n",
        "max_value = -1e18\n",
        "min_value = 1e18\n",
        "de_max_value = -1e18\n",
        "de_min_value = 1e18\n",
        "\n",
        "sample = io.loadmat(os.path.join(FEATURES_DATA_PATH, data[0]))\n",
        "# get all the de_lds feature keys since for the final model I will only use de_lds features\n",
        "de_keys = [key for key in sample.keys() if \"de_LDS\" in key]\n",
        "assert (len(de_keys) == 15)\n",
        "\n",
        "for sample in data:\n",
        "  sample = io.loadmat(os.path.join(FEATURES_DATA_PATH, sample))\n",
        "  for key in features_LDS:\n",
        "    if key in de_keys:\n",
        "      de_max_value = max(de_max_value, np.amax(sample[key]))\n",
        "      de_min_value = min(de_min_value, np.amin(sample[key]))\n",
        "    max_value = max(max_value, np.amax(sample[key]))\n",
        "    min_value = min(min_value, np.amin(sample[key]))\n",
        "print((min_value, max_value))\n",
        "print(f'de range: {(de_min_value, de_max_value)}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ivkkaf3hp-7B"
      },
      "source": [
        "#### Reformat to csv files for convenience and using tfdv "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fHFP9NZdp2Ql"
      },
      "source": [
        "# dataframe format: each row represents one data sample (one window from trial)\n",
        "# columns: all the provided features with LDS averaging for each channel and for each band\n",
        "features=['de_LDS','psd_LDS','dasm_LDS','rasm_LDS','asm_LDS','dcau_LDS']\n",
        "num_ch_per_feature = [62, 62, 27, 27, 54, 23]\n",
        "bands = [\"delta\", \"theta\", \"alpha\", \"beta\", \"gamma\"]\n",
        "columns = []\n",
        "count = 0\n",
        "\n",
        "for i, f in enumerate(features):\n",
        "  for ch in range(1, num_ch_per_feature[i]+1):\n",
        "    for b in bands:\n",
        "      columns.append(str(f + \"_\" + str(ch) + \"_\" + b))\n",
        "\n",
        " \n",
        "# add column for labels\n",
        "columns.append(\"label\")\n",
        "assert (len(columns) == (sum(i*5 for i in num_ch_per_feature)+1))\n",
        "\n",
        "# number of features 62*5 + 62*5 + 27*5 + 27*5 + 54*5 + 23*5 = 1275.\n",
        "total_num_features = len(columns)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V0XZa6GeqG_i"
      },
      "source": [
        "def get_data_from_file(file:str):\n",
        "  x = io.loadmat(os.path.join(FEATURES_DATA_PATH, file))\n",
        "  trial_data = [0] * 15\n",
        "  total_num_wind = 0\n",
        "\n",
        "  for i in range(0,90,6): # process each trial data: 90 = 15*6\n",
        "    trial = int(i//6) #0-indexed\n",
        "    f = [0] * 6\n",
        "    feature_name = features_LDS[i]\n",
        "    assert (feature_name == f\"de_LDS{trial+1}\")\n",
        "    num_wind_trial = x[feature_name].shape[1]\n",
        "    total_num_wind += num_wind_trial\n",
        "  \n",
        "    # process the entire set of 6 features\n",
        "    for j in range(6):\n",
        "      f[j] = x[features_LDS[i+j]]\n",
        "      f[j] = np.swapaxes(f[j],0,1) # swap the ch and num_wind axis\n",
        "      # concatenate all data points across channels\n",
        "      f[j] = np.reshape(f[j], (-1, num_ch_per_feature[j]*num_bands))\n",
        "      assert (f[j].shape == (num_wind_trial, 5*num_ch_per_feature[j]))\n",
        "\n",
        "      if j == 0: # de feature\n",
        "        assert (np.amax(f[j]) <= de_max_value)\n",
        "        assert (np.amin(f[j]) >= de_min_value)\n",
        "\n",
        "    # assign to each window the corresponding trial label\n",
        "    l = list([labels[trial]] * num_wind_trial)\n",
        "    trial_labels = np.array([l])\n",
        "    trial_labels = np.reshape(trial_labels, (num_wind_trial, -1))\n",
        "    assert (np.unique(trial_labels).shape == (1,))\n",
        "    assert (trial_labels[0] == labels[trial])\n",
        "\n",
        "    # concatenate features across the horizontal axis: # feature_ch_band order + an additional column for labels\n",
        "    trial_data[trial] = np.concatenate([f[idx] for idx in range(6)] + [trial_labels], 1) \n",
        "    assert (trial_data[trial].shape == (num_wind_trial, total_num_features))\n",
        "  \n",
        "  entire_file_data = np.concatenate([trial_data[idx] for idx in range(num_trials)], axis=0)\n",
        "  assert entire_file_data.shape == (total_num_wind, total_num_features)\n",
        "  assert (np.amax(entire_file_data) <= max_value)\n",
        "  assert (np.amin(entire_file_data) >= min_value)\n",
        "  \n",
        "  return entire_file_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OYYPUroFqKGK"
      },
      "source": [
        "def get_all_data_for_subject(file1, file2, file3):\n",
        "  series1 = get_data_from_file(file1)\n",
        "  series2 = get_data_from_file(file2)\n",
        "  series3 = get_data_from_file(file3)\n",
        "  series = np.concatenate([series1, series2, series3], axis=0)\n",
        "  assert (series.shape == (3*series1.shape[0], total_num_features))\n",
        "  assert (np.amax(series) <= max_value)\n",
        "  assert (np.amin(series) >= min_value)\n",
        "  return series"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ps-zaqC_qNML"
      },
      "source": [
        "all_dfs = []\n",
        "for i in range(0,45,3):\n",
        "  # get all data for each subject\n",
        "  subject_data = get_all_data_for_subject(data[i], data[i+1], data[i+2])\n",
        "  #convert numpy data to DataFrame\n",
        "  data_dict = {}\n",
        "  for j, col in enumerate(columns):\n",
        "    data_dict[col] = subject_data[:, j]\n",
        "  df = pd.DataFrame(data_dict)\n",
        "  all_dfs.append(df)\n",
        "  #save dataframe to csv\n",
        "  df.to_csv(CSV_PATH + \"/\" + \"csv_\" + str((i+1)//3) + \".csv\")\n",
        "  \n",
        "all_subjects_df = pd.concat(all_dfs)\n",
        "all_subjects_df.to_csv(CSV_PATH + \"/\" + \"csv_all_subjects.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}